{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renjian-buchai/buildingBloCS/blob/main/PillDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sGdrwnEEuUY"
      },
      "source": [
        "CSV Manipilation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U33F-g5A9kD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Retain only the \"filename\" and \"region_shape_attributes\" columns\n",
        "df = df[['filename', 'region_shape_attributes']]\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('new_file.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA763Fb6E3tk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Extract x_min, y_min, x_max, and y_max from region_shape_attributes\n",
        "df['region_shape_attributes'] = df['region_shape_attributes'].apply(lambda x: json.loads(x))\n",
        "df['x_min'] = df['region_shape_attributes'].apply(lambda x: x['x'])\n",
        "df['y_min'] = df['region_shape_attributes'].apply(lambda x: x['y'])\n",
        "df['x_max'] = df['region_shape_attributes'].apply(lambda x: x['x'] + x['width'])\n",
        "df['y_max'] = df['region_shape_attributes'].apply(lambda x: x['y'] + x['height'])\n",
        "\n",
        "# Remove the region_shape_attributes column\n",
        "df = df.drop(columns=['region_shape_attributes'])\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('new_file.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0hE9clUE2Ix"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n1cNDBmUE-uL"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "# from pyimagesearch import config\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set some constants"
      ],
      "metadata": {
        "id": "cQX85tNGHYhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTS_PATH = \"/content/Test/annotations.csv\"\n",
        "IMAGES_PATH = \"/content/Test\"\n",
        "\n",
        "TEST_FILENAMES = \"/content/output/test_images.txt\"\n",
        "PLOT_PATH = \"/content/output/plot.png\"\n",
        "MODEL_PATH = \"/content/output/detector.h5\"\n",
        "\n",
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 25\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "ULwHd_I3Hc8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = open(ANNOTS_PATH).read().strip().split(\"\\n\")\n",
        "\n",
        "\n",
        "data = []\n",
        "targets = []\n",
        "filenames = []"
      ],
      "metadata": {
        "id": "6VqwkPtPHYFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV reading and image loading"
      ],
      "metadata": {
        "id": "ZiWDU8DdHxqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for row in rows:\n",
        "\t# break the row into the filename and bounding box coordinates\n",
        "  row = row.split(\",\")\n",
        "  (filename, startX, startY, endX, endY) = row\n",
        "  imagePath = os.path.sep.join([IMAGES_PATH, filename])\n",
        "  image = cv2.imread(imagePath)\n",
        "  (h, w) = image.shape[:2]\n",
        "  # scale the bounding box coordinates relative to the spatial\n",
        "  # dimensions of the input image\n",
        "  startX = float(startX) / w\n",
        "  startY = float(startY) / h\n",
        "  endX = float(endX) / w\n",
        "  endY = float(endY) / h\n",
        "    # load the image and preprocess it\n",
        "  image = load_img(imagePath, target_size=(224, 224))\n",
        "  image = img_to_array(image)\n",
        "  # update our list of data, targets, and filenames\n",
        "  data.append(image)\n",
        "  targets.append((startX, startY, endX, endY))\n",
        "  filenames.append(filename)"
      ],
      "metadata": {
        "id": "4O5MlavhHxIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partion Dataset"
      ],
      "metadata": {
        "id": "FIIu-pIyIErq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the data and targets to NumPy arrays, scaling the input\n",
        "# pixel intensities from the range [0, 255] to [0, 1]\n",
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "targets = np.array(targets, dtype=\"float32\")\n",
        "# partition the data into training and testing splits using 90% of\n",
        "# the data for training and the remaining 10% for testing\n",
        "split = train_test_split(data, targets, filenames, test_size=0.10,\n",
        "\trandom_state=42)\n",
        "# unpack the data split\n",
        "(trainImages, testImages) = split[:2]\n",
        "(trainTargets, testTargets) = split[2:4]\n",
        "(trainFilenames, testFilenames) = split[4:]\n",
        "# write the testing filenames to disk so that we can use then\n",
        "# when evaluating/testing our bounding box regressor\n",
        "print(\"[INFO] saving testing filenames...\")\n",
        "f = open(TEST_FILENAMES, \"w\")\n",
        "f.write(\"\\n\".join(testFilenames))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "ctvoYYQKIE4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG finetuning"
      ],
      "metadata": {
        "id": "kmIPVHaVKabt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the VGG16 network, ensuring the head FC layers are left off\n",
        "vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "vgg.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = Model(inputs=vgg.input, outputs=bboxHead)\n",
        "\n",
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "opt = Adam(lr=INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "print(model.summary())\n",
        "# train the network for bounding box regression\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "H = model.fit(\n",
        "\ttrainImages, trainTargets,\n",
        "\tvalidation_data=(testImages, testTargets),\n",
        "\tbatch_size=BATCH_SIZE,\n",
        "\tepochs=NUM_EPOCHS,\n",
        "\tverbose=1)"
      ],
      "metadata": {
        "id": "pxspoS8XIiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serialise and plot training history"
      ],
      "metadata": {
        "id": "5iW0g8G0K2ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving object detector model...\")\n",
        "model.save(MODEL_PATH, save_format=\"h5\")\n",
        "# plot the model training history\n",
        "N = NUM_EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(PLOT_PATH)"
      ],
      "metadata": {
        "id": "xaor8euZK6Qd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMcrBQCkK8eOsGqbNOYBIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}