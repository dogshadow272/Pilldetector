{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1q-uD_VdeIR1lB0x9yY4YkwpFTnvRxEWx",
      "authorship_tag": "ABX9TyMYXH+MJcCvOejqWCH8Uqep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renjian-buchai/buildingBloCS/blob/main/csvtoTFRecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Object Detection API\n"
      ],
      "metadata": {
        "id": "VUYUMFT0SnYF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_HbHK3GPkxH8"
      },
      "outputs": [],
      "source": [
        "# !unzip drive/MyDrive/ExtractedSet.zip\n",
        "!pip install -q tensorflow-object-detection-api\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Requirements"
      ],
      "metadata": {
        "id": "k3m8MnEgTtFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "from object_detection.utils import dataset_util"
      ],
      "metadata": {
        "id": "Ddpq5FA9nCH0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert CSVs to dataframes\n"
      ],
      "metadata": {
        "id": "RMZVylgKl0Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ExtractedSet/annotations.csv')\n",
        "df2 = pd.read_csv('/content/ExtractedSet/annotations2.csv')\n",
        "df3 = pd.read_csv('/content/ExtractedSet/annotations3.csv')"
      ],
      "metadata": {
        "id": "_VLuqvqKm_7R"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tf examples."
      ],
      "metadata": {
        "id": "DCAxU86mS__0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf(encoded_cat_image_data,height,width,filename,xmin,xmax,ymin,ymax):\n",
        "  # height = height\n",
        "  # width = width\n",
        "  # filename = filename\n",
        "  image_format = b'jpg'\n",
        "  xmins = [xmin/ width]\n",
        "  xmaxs = [xmax /width]\n",
        "  ymins = [ymin / height]\n",
        "  ymaxs = [ymax / height]\n",
        "  classes_text = [b'Pill']\n",
        "  classes = [1]\n",
        "  filename = filename.encode()\n",
        "  tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "  'image/height': dataset_util.int64_feature(height),\n",
        "  'image/width': dataset_util.int64_feature(width),\n",
        "  'image/filename': dataset_util.bytes_feature(filename),\n",
        "  'image/source_id': dataset_util.bytes_feature(filename),\n",
        "  'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
        "  'image/format': dataset_util.bytes_feature(image_format),\n",
        "  'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "  'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "  'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "  'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "  'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "  'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }\n",
        "  ))\n",
        "  return tf_example"
      ],
      "metadata": {
        "id": "-Jxd2UjjlZcp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to convert csv from VGG image annotator to TFRecord file for training"
      ],
      "metadata": {
        "id": "1ZosAOVYTSid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = 'training.tfrecord'\n",
        "writer = tf.io.TFRecordWriter(output_file)\n",
        "\n",
        "for i in range(len(df)):\n",
        "  #encoded_image_data\n",
        "  directory_path = \"/content/ExtractedSet\"\n",
        "  filename = df.loc[i, \"filename\"]\n",
        "  full_file_path = os.path.join(directory_path, filename)\n",
        "  image = Image.open(full_file_path)\n",
        "  # with open(full_file_path, 'rb') as f:\n",
        "  #   image_bytes = f.read()\n",
        "  # encoded_image_data = bytes(image_bytes)\n",
        "  image_buffer = io.BytesIO()\n",
        "  image.save(image_buffer, format='JPEG')\n",
        "  # print(encoded_image_data)\n",
        "  encoded_image_data = (image_buffer.getvalue())\n",
        "  \n",
        "  #height and width\n",
        "  json_string = df.loc[i, \"region_shape_attributes\"]\n",
        "  json_object = json.loads(json_string)\n",
        "  width = json_object[\"width\"]\n",
        "  height = json_object[\"height\"]\n",
        "  #filename = filename\n",
        "  # df.loc[i, \"filement\"]\n",
        "  #x_min,x_max,y_min,y_max\n",
        "  x_min = df2.loc[i, \"x_min\"]\n",
        "  x_max = df2.loc[i, \"x_max\"]\n",
        "  y_min = df2.loc[i, \"y_min\"]\n",
        "  y_max = df2.loc[i, \"y_max\"]\n",
        "  filename = os.path.splitext(filename)[0]\n",
        "  example = create_tf(encoded_image_data,height,width,filename,x_min,x_max,y_min,y_max)\n",
        "  serialized_example = example.SerializeToString()\n",
        "  writer.write(serialized_example)\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "AberI6eRtPPL"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}